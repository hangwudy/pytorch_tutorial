{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987abe54-783f-4e5b-a0a2-99083a90d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeee7cab-911b-4a42-9196-982d478041a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/hangwu/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630839582/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c5804e-9823-4337-879b-047b3c9dc258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1feb79-115d-4b59-9f5d-9f5ef48031ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f59ae-7b9d-4007-8c1a-b55d0a8f0af8",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccf77be-e8cd-4b5b-b225-f23b70728e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca109427-3290-4a17-9745-17f078152458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0339,  0.0312, -0.0283,  ..., -0.0243,  0.0161,  0.0173],\n",
      "        [ 0.0111, -0.0298, -0.0338,  ...,  0.0110, -0.0276, -0.0092]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0071,  0.0128], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0312,  0.0215, -0.0039,  ...,  0.0057,  0.0367,  0.0050],\n",
      "        [ 0.0170, -0.0413, -0.0231,  ...,  0.0032,  0.0127, -0.0068]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0143,  0.0212], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 2.6357e-02, -3.4223e-02, -1.4622e-02,  ...,  2.4731e-02,\n",
      "          4.1379e-02, -3.7933e-02],\n",
      "        [ 1.6632e-02, -8.6329e-03,  2.3370e-02,  ...,  3.6204e-02,\n",
      "         -9.5584e-05, -2.6854e-02]], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0224, -0.0096], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff67dde-0352-4a59-940b-7efd73c076c3",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7201e722-09ff-4f28-ba95-4e4e6f89b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c695f74-d0e6-4d98-adae-f30d62087217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166a7e5a-cece-4cfa-9720-862f71841f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2e4e19-8eca-47c3-a79b-3e5106a09e99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296282  [    0/60000]\n",
      "loss: 2.287001  [ 6400/60000]\n",
      "loss: 2.270160  [12800/60000]\n",
      "loss: 2.265982  [19200/60000]\n",
      "loss: 2.248585  [25600/60000]\n",
      "loss: 2.217779  [32000/60000]\n",
      "loss: 2.222608  [38400/60000]\n",
      "loss: 2.190046  [44800/60000]\n",
      "loss: 2.188668  [51200/60000]\n",
      "loss: 2.161383  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.153739 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165823  [    0/60000]\n",
      "loss: 2.155751  [ 6400/60000]\n",
      "loss: 2.101481  [12800/60000]\n",
      "loss: 2.115294  [19200/60000]\n",
      "loss: 2.065696  [25600/60000]\n",
      "loss: 2.002074  [32000/60000]\n",
      "loss: 2.031074  [38400/60000]\n",
      "loss: 1.953389  [44800/60000]\n",
      "loss: 1.966730  [51200/60000]\n",
      "loss: 1.891770  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.891915 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.928685  [    0/60000]\n",
      "loss: 1.893238  [ 6400/60000]\n",
      "loss: 1.785939  [12800/60000]\n",
      "loss: 1.823003  [19200/60000]\n",
      "loss: 1.716830  [25600/60000]\n",
      "loss: 1.667875  [32000/60000]\n",
      "loss: 1.688789  [38400/60000]\n",
      "loss: 1.595334  [44800/60000]\n",
      "loss: 1.627874  [51200/60000]\n",
      "loss: 1.524427  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.540034 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.608368  [    0/60000]\n",
      "loss: 1.565619  [ 6400/60000]\n",
      "loss: 1.429286  [12800/60000]\n",
      "loss: 1.493602  [19200/60000]\n",
      "loss: 1.381425  [25600/60000]\n",
      "loss: 1.377550  [32000/60000]\n",
      "loss: 1.384176  [38400/60000]\n",
      "loss: 1.314411  [44800/60000]\n",
      "loss: 1.354376  [51200/60000]\n",
      "loss: 1.258837  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.278472 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.356489  [    0/60000]\n",
      "loss: 1.330231  [ 6400/60000]\n",
      "loss: 1.176225  [12800/60000]\n",
      "loss: 1.272870  [19200/60000]\n",
      "loss: 1.155430  [25600/60000]\n",
      "loss: 1.178966  [32000/60000]\n",
      "loss: 1.189102  [38400/60000]\n",
      "loss: 1.131048  [44800/60000]\n",
      "loss: 1.176911  [51200/60000]\n",
      "loss: 1.094686  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.109870 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.181453  [    0/60000]\n",
      "loss: 1.175782  [ 6400/60000]\n",
      "loss: 1.004394  [12800/60000]\n",
      "loss: 1.131756  [19200/60000]\n",
      "loss: 1.010728  [25600/60000]\n",
      "loss: 1.040710  [32000/60000]\n",
      "loss: 1.064121  [38400/60000]\n",
      "loss: 1.009402  [44800/60000]\n",
      "loss: 1.058403  [51200/60000]\n",
      "loss: 0.989106  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.998450 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.057242  [    0/60000]\n",
      "loss: 1.073410  [ 6400/60000]\n",
      "loss: 0.884620  [12800/60000]\n",
      "loss: 1.036359  [19200/60000]\n",
      "loss: 0.917082  [25600/60000]\n",
      "loss: 0.942020  [32000/60000]\n",
      "loss: 0.981029  [38400/60000]\n",
      "loss: 0.928040  [44800/60000]\n",
      "loss: 0.974815  [51200/60000]\n",
      "loss: 0.918004  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.921730 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.964954  [    0/60000]\n",
      "loss: 1.001988  [ 6400/60000]\n",
      "loss: 0.798002  [12800/60000]\n",
      "loss: 0.968622  [19200/60000]\n",
      "loss: 0.854567  [25600/60000]\n",
      "loss: 0.869334  [32000/60000]\n",
      "loss: 0.922652  [38400/60000]\n",
      "loss: 0.873048  [44800/60000]\n",
      "loss: 0.914035  [51200/60000]\n",
      "loss: 0.867201  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.866643 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.894149  [    0/60000]\n",
      "loss: 0.948985  [ 6400/60000]\n",
      "loss: 0.733130  [12800/60000]\n",
      "loss: 0.918428  [19200/60000]\n",
      "loss: 0.810546  [25600/60000]\n",
      "loss: 0.814867  [32000/60000]\n",
      "loss: 0.879086  [38400/60000]\n",
      "loss: 0.835029  [44800/60000]\n",
      "loss: 0.868885  [51200/60000]\n",
      "loss: 0.829006  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.825414 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.838341  [    0/60000]\n",
      "loss: 0.907084  [ 6400/60000]\n",
      "loss: 0.683006  [12800/60000]\n",
      "loss: 0.880030  [19200/60000]\n",
      "loss: 0.777655  [25600/60000]\n",
      "loss: 0.773237  [32000/60000]\n",
      "loss: 0.844655  [38400/60000]\n",
      "loss: 0.807590  [44800/60000]\n",
      "loss: 0.834104  [51200/60000]\n",
      "loss: 0.798638  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.793136 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.792679  [    0/60000]\n",
      "loss: 0.872298  [ 6400/60000]\n",
      "loss: 0.642829  [12800/60000]\n",
      "loss: 0.849663  [19200/60000]\n",
      "loss: 0.751806  [25600/60000]\n",
      "loss: 0.740708  [32000/60000]\n",
      "loss: 0.816089  [38400/60000]\n",
      "loss: 0.786609  [44800/60000]\n",
      "loss: 0.806478  [51200/60000]\n",
      "loss: 0.773395  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.766748 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.754180  [    0/60000]\n",
      "loss: 0.842066  [ 6400/60000]\n",
      "loss: 0.609815  [12800/60000]\n",
      "loss: 0.825032  [19200/60000]\n",
      "loss: 0.730526  [25600/60000]\n",
      "loss: 0.714725  [32000/60000]\n",
      "loss: 0.791121  [38400/60000]\n",
      "loss: 0.769629  [44800/60000]\n",
      "loss: 0.783703  [51200/60000]\n",
      "loss: 0.751845  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.744308 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.720802  [    0/60000]\n",
      "loss: 0.815100  [ 6400/60000]\n",
      "loss: 0.581959  [12800/60000]\n",
      "loss: 0.804220  [19200/60000]\n",
      "loss: 0.712489  [25600/60000]\n",
      "loss: 0.693449  [32000/60000]\n",
      "loss: 0.768552  [38400/60000]\n",
      "loss: 0.754937  [44800/60000]\n",
      "loss: 0.764229  [51200/60000]\n",
      "loss: 0.732890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.724561 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.691412  [    0/60000]\n",
      "loss: 0.790559  [ 6400/60000]\n",
      "loss: 0.557931  [12800/60000]\n",
      "loss: 0.786030  [19200/60000]\n",
      "loss: 0.697018  [25600/60000]\n",
      "loss: 0.675552  [32000/60000]\n",
      "loss: 0.747674  [38400/60000]\n",
      "loss: 0.741813  [44800/60000]\n",
      "loss: 0.747224  [51200/60000]\n",
      "loss: 0.715800  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.706763 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.665119  [    0/60000]\n",
      "loss: 0.767809  [ 6400/60000]\n",
      "loss: 0.536925  [12800/60000]\n",
      "loss: 0.769741  [19200/60000]\n",
      "loss: 0.683381  [25600/60000]\n",
      "loss: 0.660296  [32000/60000]\n",
      "loss: 0.728193  [38400/60000]\n",
      "loss: 0.729856  [44800/60000]\n",
      "loss: 0.732077  [51200/60000]\n",
      "loss: 0.700253  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.690507 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.641493  [    0/60000]\n",
      "loss: 0.746788  [ 6400/60000]\n",
      "loss: 0.518368  [12800/60000]\n",
      "loss: 0.754929  [19200/60000]\n",
      "loss: 0.671325  [25600/60000]\n",
      "loss: 0.647056  [32000/60000]\n",
      "loss: 0.709791  [38400/60000]\n",
      "loss: 0.718910  [44800/60000]\n",
      "loss: 0.718531  [51200/60000]\n",
      "loss: 0.685840  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.675513 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.620115  [    0/60000]\n",
      "loss: 0.727378  [ 6400/60000]\n",
      "loss: 0.501708  [12800/60000]\n",
      "loss: 0.741211  [19200/60000]\n",
      "loss: 0.660539  [25600/60000]\n",
      "loss: 0.635436  [32000/60000]\n",
      "loss: 0.692472  [38400/60000]\n",
      "loss: 0.708854  [44800/60000]\n",
      "loss: 0.706447  [51200/60000]\n",
      "loss: 0.672377  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.661608 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.600820  [    0/60000]\n",
      "loss: 0.709357  [ 6400/60000]\n",
      "loss: 0.486618  [12800/60000]\n",
      "loss: 0.728520  [19200/60000]\n",
      "loss: 0.651068  [25600/60000]\n",
      "loss: 0.625168  [32000/60000]\n",
      "loss: 0.676307  [38400/60000]\n",
      "loss: 0.699871  [44800/60000]\n",
      "loss: 0.695839  [51200/60000]\n",
      "loss: 0.659772  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.648757 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.583300  [    0/60000]\n",
      "loss: 0.692592  [ 6400/60000]\n",
      "loss: 0.473193  [12800/60000]\n",
      "loss: 0.716586  [19200/60000]\n",
      "loss: 0.642581  [25600/60000]\n",
      "loss: 0.616156  [32000/60000]\n",
      "loss: 0.661026  [38400/60000]\n",
      "loss: 0.692018  [44800/60000]\n",
      "loss: 0.686619  [51200/60000]\n",
      "loss: 0.647939  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.636871 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.567268  [    0/60000]\n",
      "loss: 0.676970  [ 6400/60000]\n",
      "loss: 0.461071  [12800/60000]\n",
      "loss: 0.705407  [19200/60000]\n",
      "loss: 0.634795  [25600/60000]\n",
      "loss: 0.608201  [32000/60000]\n",
      "loss: 0.646695  [38400/60000]\n",
      "loss: 0.685129  [44800/60000]\n",
      "loss: 0.678520  [51200/60000]\n",
      "loss: 0.636807  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.625868 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.552641  [    0/60000]\n",
      "loss: 0.662432  [ 6400/60000]\n",
      "loss: 0.450012  [12800/60000]\n",
      "loss: 0.694912  [19200/60000]\n",
      "loss: 0.627674  [25600/60000]\n",
      "loss: 0.601106  [32000/60000]\n",
      "loss: 0.633272  [38400/60000]\n",
      "loss: 0.679233  [44800/60000]\n",
      "loss: 0.671474  [51200/60000]\n",
      "loss: 0.626260  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.615680 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.539217  [    0/60000]\n",
      "loss: 0.648921  [ 6400/60000]\n",
      "loss: 0.439905  [12800/60000]\n",
      "loss: 0.685047  [19200/60000]\n",
      "loss: 0.621091  [25600/60000]\n",
      "loss: 0.594708  [32000/60000]\n",
      "loss: 0.620694  [38400/60000]\n",
      "loss: 0.674312  [44800/60000]\n",
      "loss: 0.665416  [51200/60000]\n",
      "loss: 0.616271  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.606245 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.526887  [    0/60000]\n",
      "loss: 0.636357  [ 6400/60000]\n",
      "loss: 0.430607  [12800/60000]\n",
      "loss: 0.675740  [19200/60000]\n",
      "loss: 0.614870  [25600/60000]\n",
      "loss: 0.588873  [32000/60000]\n",
      "loss: 0.608914  [38400/60000]\n",
      "loss: 0.670292  [44800/60000]\n",
      "loss: 0.660315  [51200/60000]\n",
      "loss: 0.606762  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.597502 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.515456  [    0/60000]\n",
      "loss: 0.624653  [ 6400/60000]\n",
      "loss: 0.421993  [12800/60000]\n",
      "loss: 0.666927  [19200/60000]\n",
      "loss: 0.608905  [25600/60000]\n",
      "loss: 0.583473  [32000/60000]\n",
      "loss: 0.597838  [38400/60000]\n",
      "loss: 0.667084  [44800/60000]\n",
      "loss: 0.655964  [51200/60000]\n",
      "loss: 0.597616  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.589390 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.504778  [    0/60000]\n",
      "loss: 0.613723  [ 6400/60000]\n",
      "loss: 0.414036  [12800/60000]\n",
      "loss: 0.658586  [19200/60000]\n",
      "loss: 0.603179  [25600/60000]\n",
      "loss: 0.578474  [32000/60000]\n",
      "loss: 0.587447  [38400/60000]\n",
      "loss: 0.664580  [44800/60000]\n",
      "loss: 0.652270  [51200/60000]\n",
      "loss: 0.588720  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.581874 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.494791  [    0/60000]\n",
      "loss: 0.603580  [ 6400/60000]\n",
      "loss: 0.406709  [12800/60000]\n",
      "loss: 0.650711  [19200/60000]\n",
      "loss: 0.597473  [25600/60000]\n",
      "loss: 0.573727  [32000/60000]\n",
      "loss: 0.577761  [38400/60000]\n",
      "loss: 0.662651  [44800/60000]\n",
      "loss: 0.649086  [51200/60000]\n",
      "loss: 0.580152  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.574895 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.485409  [    0/60000]\n",
      "loss: 0.594143  [ 6400/60000]\n",
      "loss: 0.399871  [12800/60000]\n",
      "loss: 0.643296  [19200/60000]\n",
      "loss: 0.591794  [25600/60000]\n",
      "loss: 0.569185  [32000/60000]\n",
      "loss: 0.568727  [38400/60000]\n",
      "loss: 0.661277  [44800/60000]\n",
      "loss: 0.646295  [51200/60000]\n",
      "loss: 0.571844  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.568407 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.476579  [    0/60000]\n",
      "loss: 0.585359  [ 6400/60000]\n",
      "loss: 0.393469  [12800/60000]\n",
      "loss: 0.636270  [19200/60000]\n",
      "loss: 0.586169  [25600/60000]\n",
      "loss: 0.564755  [32000/60000]\n",
      "loss: 0.560263  [38400/60000]\n",
      "loss: 0.660401  [44800/60000]\n",
      "loss: 0.643856  [51200/60000]\n",
      "loss: 0.563787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.562365 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.468234  [    0/60000]\n",
      "loss: 0.577157  [ 6400/60000]\n",
      "loss: 0.387516  [12800/60000]\n",
      "loss: 0.629587  [19200/60000]\n",
      "loss: 0.580471  [25600/60000]\n",
      "loss: 0.560419  [32000/60000]\n",
      "loss: 0.552339  [38400/60000]\n",
      "loss: 0.659939  [44800/60000]\n",
      "loss: 0.641649  [51200/60000]\n",
      "loss: 0.555950  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.556733 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.460333  [    0/60000]\n",
      "loss: 0.569502  [ 6400/60000]\n",
      "loss: 0.381946  [12800/60000]\n",
      "loss: 0.623206  [19200/60000]\n",
      "loss: 0.574762  [25600/60000]\n",
      "loss: 0.556196  [32000/60000]\n",
      "loss: 0.544928  [38400/60000]\n",
      "loss: 0.659848  [44800/60000]\n",
      "loss: 0.639661  [51200/60000]\n",
      "loss: 0.548320  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551479 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.452857  [    0/60000]\n",
      "loss: 0.562326  [ 6400/60000]\n",
      "loss: 0.376732  [12800/60000]\n",
      "loss: 0.617090  [19200/60000]\n",
      "loss: 0.569038  [25600/60000]\n",
      "loss: 0.552000  [32000/60000]\n",
      "loss: 0.538004  [38400/60000]\n",
      "loss: 0.660019  [44800/60000]\n",
      "loss: 0.637830  [51200/60000]\n",
      "loss: 0.540896  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.546570 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.445751  [    0/60000]\n",
      "loss: 0.555575  [ 6400/60000]\n",
      "loss: 0.371856  [12800/60000]\n",
      "loss: 0.611211  [19200/60000]\n",
      "loss: 0.563354  [25600/60000]\n",
      "loss: 0.547809  [32000/60000]\n",
      "loss: 0.531546  [38400/60000]\n",
      "loss: 0.660423  [44800/60000]\n",
      "loss: 0.636159  [51200/60000]\n",
      "loss: 0.533783  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.541981 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.438961  [    0/60000]\n",
      "loss: 0.549280  [ 6400/60000]\n",
      "loss: 0.367237  [12800/60000]\n",
      "loss: 0.605511  [19200/60000]\n",
      "loss: 0.557766  [25600/60000]\n",
      "loss: 0.543668  [32000/60000]\n",
      "loss: 0.525498  [38400/60000]\n",
      "loss: 0.660894  [44800/60000]\n",
      "loss: 0.634580  [51200/60000]\n",
      "loss: 0.526880  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.537679 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.432551  [    0/60000]\n",
      "loss: 0.543428  [ 6400/60000]\n",
      "loss: 0.362929  [12800/60000]\n",
      "loss: 0.600024  [19200/60000]\n",
      "loss: 0.552184  [25600/60000]\n",
      "loss: 0.539553  [32000/60000]\n",
      "loss: 0.519858  [38400/60000]\n",
      "loss: 0.661497  [44800/60000]\n",
      "loss: 0.633037  [51200/60000]\n",
      "loss: 0.520248  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.533640 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.426405  [    0/60000]\n",
      "loss: 0.537963  [ 6400/60000]\n",
      "loss: 0.358806  [12800/60000]\n",
      "loss: 0.594724  [19200/60000]\n",
      "loss: 0.546698  [25600/60000]\n",
      "loss: 0.535419  [32000/60000]\n",
      "loss: 0.514547  [38400/60000]\n",
      "loss: 0.662094  [44800/60000]\n",
      "loss: 0.631539  [51200/60000]\n",
      "loss: 0.513890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.529841 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.420510  [    0/60000]\n",
      "loss: 0.532888  [ 6400/60000]\n",
      "loss: 0.354913  [12800/60000]\n",
      "loss: 0.589634  [19200/60000]\n",
      "loss: 0.541306  [25600/60000]\n",
      "loss: 0.531276  [32000/60000]\n",
      "loss: 0.509594  [38400/60000]\n",
      "loss: 0.662694  [44800/60000]\n",
      "loss: 0.629987  [51200/60000]\n",
      "loss: 0.507787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.526265 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.414855  [    0/60000]\n",
      "loss: 0.528116  [ 6400/60000]\n",
      "loss: 0.351234  [12800/60000]\n",
      "loss: 0.584728  [19200/60000]\n",
      "loss: 0.536037  [25600/60000]\n",
      "loss: 0.527189  [32000/60000]\n",
      "loss: 0.504884  [38400/60000]\n",
      "loss: 0.663215  [44800/60000]\n",
      "loss: 0.628457  [51200/60000]\n",
      "loss: 0.501978  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.522891 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.409411  [    0/60000]\n",
      "loss: 0.523638  [ 6400/60000]\n",
      "loss: 0.347758  [12800/60000]\n",
      "loss: 0.580015  [19200/60000]\n",
      "loss: 0.530849  [25600/60000]\n",
      "loss: 0.522951  [32000/60000]\n",
      "loss: 0.500323  [38400/60000]\n",
      "loss: 0.663703  [44800/60000]\n",
      "loss: 0.626869  [51200/60000]\n",
      "loss: 0.496375  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.519701 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.404207  [    0/60000]\n",
      "loss: 0.519450  [ 6400/60000]\n",
      "loss: 0.344478  [12800/60000]\n",
      "loss: 0.575430  [19200/60000]\n",
      "loss: 0.525850  [25600/60000]\n",
      "loss: 0.518735  [32000/60000]\n",
      "loss: 0.496165  [38400/60000]\n",
      "loss: 0.664070  [44800/60000]\n",
      "loss: 0.625294  [51200/60000]\n",
      "loss: 0.491005  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.516684 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.399179  [    0/60000]\n",
      "loss: 0.515452  [ 6400/60000]\n",
      "loss: 0.341390  [12800/60000]\n",
      "loss: 0.571012  [19200/60000]\n",
      "loss: 0.521026  [25600/60000]\n",
      "loss: 0.514718  [32000/60000]\n",
      "loss: 0.492214  [38400/60000]\n",
      "loss: 0.664318  [44800/60000]\n",
      "loss: 0.623669  [51200/60000]\n",
      "loss: 0.485869  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.513825 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.394317  [    0/60000]\n",
      "loss: 0.511647  [ 6400/60000]\n",
      "loss: 0.338428  [12800/60000]\n",
      "loss: 0.566729  [19200/60000]\n",
      "loss: 0.516265  [25600/60000]\n",
      "loss: 0.510826  [32000/60000]\n",
      "loss: 0.488502  [38400/60000]\n",
      "loss: 0.664473  [44800/60000]\n",
      "loss: 0.621995  [51200/60000]\n",
      "loss: 0.481005  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.511112 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.389657  [    0/60000]\n",
      "loss: 0.508030  [ 6400/60000]\n",
      "loss: 0.335637  [12800/60000]\n",
      "loss: 0.562590  [19200/60000]\n",
      "loss: 0.511686  [25600/60000]\n",
      "loss: 0.507019  [32000/60000]\n",
      "loss: 0.484953  [38400/60000]\n",
      "loss: 0.664490  [44800/60000]\n",
      "loss: 0.620333  [51200/60000]\n",
      "loss: 0.476381  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.508529 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.385156  [    0/60000]\n",
      "loss: 0.504587  [ 6400/60000]\n",
      "loss: 0.332947  [12800/60000]\n",
      "loss: 0.558561  [19200/60000]\n",
      "loss: 0.507186  [25600/60000]\n",
      "loss: 0.503255  [32000/60000]\n",
      "loss: 0.481556  [38400/60000]\n",
      "loss: 0.664324  [44800/60000]\n",
      "loss: 0.618616  [51200/60000]\n",
      "loss: 0.472032  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.506066 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.380821  [    0/60000]\n",
      "loss: 0.501293  [ 6400/60000]\n",
      "loss: 0.330364  [12800/60000]\n",
      "loss: 0.554666  [19200/60000]\n",
      "loss: 0.502808  [25600/60000]\n",
      "loss: 0.499537  [32000/60000]\n",
      "loss: 0.478319  [38400/60000]\n",
      "loss: 0.663962  [44800/60000]\n",
      "loss: 0.616856  [51200/60000]\n",
      "loss: 0.467844  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.503711 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.376610  [    0/60000]\n",
      "loss: 0.498156  [ 6400/60000]\n",
      "loss: 0.327850  [12800/60000]\n",
      "loss: 0.550909  [19200/60000]\n",
      "loss: 0.498554  [25600/60000]\n",
      "loss: 0.495922  [32000/60000]\n",
      "loss: 0.475288  [38400/60000]\n",
      "loss: 0.663454  [44800/60000]\n",
      "loss: 0.615140  [51200/60000]\n",
      "loss: 0.463961  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.501462 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.372533  [    0/60000]\n",
      "loss: 0.495138  [ 6400/60000]\n",
      "loss: 0.325436  [12800/60000]\n",
      "loss: 0.547294  [19200/60000]\n",
      "loss: 0.494450  [25600/60000]\n",
      "loss: 0.492450  [32000/60000]\n",
      "loss: 0.472407  [38400/60000]\n",
      "loss: 0.662868  [44800/60000]\n",
      "loss: 0.613445  [51200/60000]\n",
      "loss: 0.460265  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499306 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.368569  [    0/60000]\n",
      "loss: 0.492279  [ 6400/60000]\n",
      "loss: 0.323106  [12800/60000]\n",
      "loss: 0.543839  [19200/60000]\n",
      "loss: 0.490458  [25600/60000]\n",
      "loss: 0.489066  [32000/60000]\n",
      "loss: 0.469641  [38400/60000]\n",
      "loss: 0.662155  [44800/60000]\n",
      "loss: 0.611684  [51200/60000]\n",
      "loss: 0.456786  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497241 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.364732  [    0/60000]\n",
      "loss: 0.489545  [ 6400/60000]\n",
      "loss: 0.320862  [12800/60000]\n",
      "loss: 0.540483  [19200/60000]\n",
      "loss: 0.486581  [25600/60000]\n",
      "loss: 0.485809  [32000/60000]\n",
      "loss: 0.466975  [38400/60000]\n",
      "loss: 0.661322  [44800/60000]\n",
      "loss: 0.609918  [51200/60000]\n",
      "loss: 0.453501  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.495255 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.361013  [    0/60000]\n",
      "loss: 0.486934  [ 6400/60000]\n",
      "loss: 0.318708  [12800/60000]\n",
      "loss: 0.537263  [19200/60000]\n",
      "loss: 0.482790  [25600/60000]\n",
      "loss: 0.482711  [32000/60000]\n",
      "loss: 0.464435  [38400/60000]\n",
      "loss: 0.660392  [44800/60000]\n",
      "loss: 0.608142  [51200/60000]\n",
      "loss: 0.450405  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.493343 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.357436  [    0/60000]\n",
      "loss: 0.484428  [ 6400/60000]\n",
      "loss: 0.316637  [12800/60000]\n",
      "loss: 0.534156  [19200/60000]\n",
      "loss: 0.479136  [25600/60000]\n",
      "loss: 0.479735  [32000/60000]\n",
      "loss: 0.461986  [38400/60000]\n",
      "loss: 0.659319  [44800/60000]\n",
      "loss: 0.606350  [51200/60000]\n",
      "loss: 0.447499  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.491499 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7387c147-38b1-40af-8721-d95bec952e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_1010.pth\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "torch.save(model.state_dict(), \"model_1010.pth\")\n",
    "print(\"Saved PyTorch Model State to model_1010.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e41f6e0-e509-4ddc-a300-57ea878b140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model_1010.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5c99cf-7001-460a-8728-50c5ae01c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29825b5b-9273-42b9-9a5d-67a3e3ba3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2936213d-7d4f-4662-afe8-81266fba1345",
   "metadata": {},
   "source": [
    "# Saving and Loading Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ca5ffa-ca19-4926-ab72-78c5110de58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/hangwu/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'vgg_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfeb14fb-c99a-4ce2-aeb6-b94def290729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('vgg_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eac725-1300-4e65-b931-f535005168fe",
   "metadata": {},
   "source": [
    "# Saving and Loading Models with Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f00f58-ddde-495e-abf3-13af1723e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'vgg_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "327648c2-8e22-4a39-9faf-b35f477cd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('vgg_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250606b5-fb2c-4daf-b121-f88984c981e7",
   "metadata": {},
   "source": [
    "# Exporting Model to ONNX\n",
    "PyTorch also has native ONNX export support. Given the dynamic nature of the PyTorch execution graph, however, the export process must traverse the execution graph to produce a persisted ONNX model. For this reason, a test variable of the appropriate size should be passed in to the export routine (in our case, we will create a dummy zero tensor of the correct size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "510f8907-0f36-41c8-876a-f265ff97628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,3,224,224))\n",
    "onnx.export(model, input_image, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89336f1-f4aa-4357-9fde-9ced1601e0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

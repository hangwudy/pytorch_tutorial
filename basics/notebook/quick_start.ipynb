{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987abe54-783f-4e5b-a0a2-99083a90d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeee7cab-911b-4a42-9196-982d478041a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hangwu/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630839582/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c5804e-9823-4337-879b-047b3c9dc258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1feb79-115d-4b59-9f5d-9f5ef48031ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f59ae-7b9d-4007-8c1a-b55d0a8f0af8",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ccf77be-e8cd-4b5b-b225-f23b70728e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca109427-3290-4a17-9745-17f078152458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0196, -0.0326,  0.0123,  ..., -0.0197, -0.0020, -0.0294],\n",
      "        [ 0.0129,  0.0056,  0.0136,  ..., -0.0067, -0.0016, -0.0090]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0302, -0.0296], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0315,  0.0412, -0.0364,  ..., -0.0395,  0.0359, -0.0165],\n",
      "        [ 0.0354,  0.0333, -0.0042,  ..., -0.0329, -0.0360, -0.0035]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0353, 0.0363], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0180,  0.0214,  0.0277,  ..., -0.0140, -0.0044,  0.0188],\n",
      "        [-0.0311, -0.0045,  0.0128,  ...,  0.0329,  0.0252,  0.0022]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0303,  0.0377], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e092c2c-d792-4788-a1ee-ec6c55c6f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "# nn.Softmax dim = 1, because there is a batch dimension\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff67dde-0352-4a59-940b-7efd73c076c3",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7201e722-09ff-4f28-ba95-4e4e6f89b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c695f74-d0e6-4d98-adae-f30d62087217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166a7e5a-cece-4cfa-9720-862f71841f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528e81b-08f6-4d3e-b818-c9ba67f3d37c",
   "metadata": {},
   "source": [
    "## Note\n",
    "Inside the training loop, optimization happens in three steps:\n",
    "- Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "- Backpropagate the prediction loss with a call to loss.backwards(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "- Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2e4e19-8eca-47c3-a79b-3e5106a09e99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296282  [    0/60000]\n",
      "loss: 2.287001  [ 6400/60000]\n",
      "loss: 2.270160  [12800/60000]\n",
      "loss: 2.265982  [19200/60000]\n",
      "loss: 2.248585  [25600/60000]\n",
      "loss: 2.217779  [32000/60000]\n",
      "loss: 2.222608  [38400/60000]\n",
      "loss: 2.190046  [44800/60000]\n",
      "loss: 2.188668  [51200/60000]\n",
      "loss: 2.161383  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.153739 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165823  [    0/60000]\n",
      "loss: 2.155751  [ 6400/60000]\n",
      "loss: 2.101481  [12800/60000]\n",
      "loss: 2.115294  [19200/60000]\n",
      "loss: 2.065696  [25600/60000]\n",
      "loss: 2.002074  [32000/60000]\n",
      "loss: 2.031074  [38400/60000]\n",
      "loss: 1.953389  [44800/60000]\n",
      "loss: 1.966730  [51200/60000]\n",
      "loss: 1.891770  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.891915 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.928685  [    0/60000]\n",
      "loss: 1.893238  [ 6400/60000]\n",
      "loss: 1.785939  [12800/60000]\n",
      "loss: 1.823003  [19200/60000]\n",
      "loss: 1.716830  [25600/60000]\n",
      "loss: 1.667875  [32000/60000]\n",
      "loss: 1.688789  [38400/60000]\n",
      "loss: 1.595334  [44800/60000]\n",
      "loss: 1.627874  [51200/60000]\n",
      "loss: 1.524427  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.540034 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.608368  [    0/60000]\n",
      "loss: 1.565619  [ 6400/60000]\n",
      "loss: 1.429286  [12800/60000]\n",
      "loss: 1.493602  [19200/60000]\n",
      "loss: 1.381425  [25600/60000]\n",
      "loss: 1.377550  [32000/60000]\n",
      "loss: 1.384176  [38400/60000]\n",
      "loss: 1.314411  [44800/60000]\n",
      "loss: 1.354376  [51200/60000]\n",
      "loss: 1.258837  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.278472 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.356489  [    0/60000]\n",
      "loss: 1.330231  [ 6400/60000]\n",
      "loss: 1.176225  [12800/60000]\n",
      "loss: 1.272870  [19200/60000]\n",
      "loss: 1.155430  [25600/60000]\n",
      "loss: 1.178966  [32000/60000]\n",
      "loss: 1.189102  [38400/60000]\n",
      "loss: 1.131048  [44800/60000]\n",
      "loss: 1.176911  [51200/60000]\n",
      "loss: 1.094686  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.109870 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.181453  [    0/60000]\n",
      "loss: 1.175782  [ 6400/60000]\n",
      "loss: 1.004394  [12800/60000]\n",
      "loss: 1.131756  [19200/60000]\n",
      "loss: 1.010728  [25600/60000]\n",
      "loss: 1.040710  [32000/60000]\n",
      "loss: 1.064121  [38400/60000]\n",
      "loss: 1.009402  [44800/60000]\n",
      "loss: 1.058403  [51200/60000]\n",
      "loss: 0.989106  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.998450 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.057242  [    0/60000]\n",
      "loss: 1.073410  [ 6400/60000]\n",
      "loss: 0.884620  [12800/60000]\n",
      "loss: 1.036359  [19200/60000]\n",
      "loss: 0.917082  [25600/60000]\n",
      "loss: 0.942020  [32000/60000]\n",
      "loss: 0.981029  [38400/60000]\n",
      "loss: 0.928040  [44800/60000]\n",
      "loss: 0.974815  [51200/60000]\n",
      "loss: 0.918004  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.921730 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.964954  [    0/60000]\n",
      "loss: 1.001988  [ 6400/60000]\n",
      "loss: 0.798002  [12800/60000]\n",
      "loss: 0.968622  [19200/60000]\n",
      "loss: 0.854567  [25600/60000]\n",
      "loss: 0.869334  [32000/60000]\n",
      "loss: 0.922652  [38400/60000]\n",
      "loss: 0.873048  [44800/60000]\n",
      "loss: 0.914035  [51200/60000]\n",
      "loss: 0.867201  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.866643 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.894149  [    0/60000]\n",
      "loss: 0.948985  [ 6400/60000]\n",
      "loss: 0.733130  [12800/60000]\n",
      "loss: 0.918428  [19200/60000]\n",
      "loss: 0.810546  [25600/60000]\n",
      "loss: 0.814867  [32000/60000]\n",
      "loss: 0.879086  [38400/60000]\n",
      "loss: 0.835029  [44800/60000]\n",
      "loss: 0.868885  [51200/60000]\n",
      "loss: 0.829006  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.825414 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.838341  [    0/60000]\n",
      "loss: 0.907084  [ 6400/60000]\n",
      "loss: 0.683006  [12800/60000]\n",
      "loss: 0.880030  [19200/60000]\n",
      "loss: 0.777655  [25600/60000]\n",
      "loss: 0.773237  [32000/60000]\n",
      "loss: 0.844655  [38400/60000]\n",
      "loss: 0.807590  [44800/60000]\n",
      "loss: 0.834104  [51200/60000]\n",
      "loss: 0.798638  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.793136 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.792679  [    0/60000]\n",
      "loss: 0.872298  [ 6400/60000]\n",
      "loss: 0.642829  [12800/60000]\n",
      "loss: 0.849663  [19200/60000]\n",
      "loss: 0.751806  [25600/60000]\n",
      "loss: 0.740708  [32000/60000]\n",
      "loss: 0.816089  [38400/60000]\n",
      "loss: 0.786609  [44800/60000]\n",
      "loss: 0.806478  [51200/60000]\n",
      "loss: 0.773395  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.766748 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.754180  [    0/60000]\n",
      "loss: 0.842066  [ 6400/60000]\n",
      "loss: 0.609815  [12800/60000]\n",
      "loss: 0.825032  [19200/60000]\n",
      "loss: 0.730526  [25600/60000]\n",
      "loss: 0.714725  [32000/60000]\n",
      "loss: 0.791121  [38400/60000]\n",
      "loss: 0.769629  [44800/60000]\n",
      "loss: 0.783703  [51200/60000]\n",
      "loss: 0.751845  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.744308 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.720802  [    0/60000]\n",
      "loss: 0.815100  [ 6400/60000]\n",
      "loss: 0.581959  [12800/60000]\n",
      "loss: 0.804220  [19200/60000]\n",
      "loss: 0.712489  [25600/60000]\n",
      "loss: 0.693449  [32000/60000]\n",
      "loss: 0.768552  [38400/60000]\n",
      "loss: 0.754937  [44800/60000]\n",
      "loss: 0.764229  [51200/60000]\n",
      "loss: 0.732890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.724561 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.691412  [    0/60000]\n",
      "loss: 0.790559  [ 6400/60000]\n",
      "loss: 0.557931  [12800/60000]\n",
      "loss: 0.786030  [19200/60000]\n",
      "loss: 0.697018  [25600/60000]\n",
      "loss: 0.675552  [32000/60000]\n",
      "loss: 0.747674  [38400/60000]\n",
      "loss: 0.741813  [44800/60000]\n",
      "loss: 0.747224  [51200/60000]\n",
      "loss: 0.715800  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.706763 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.665119  [    0/60000]\n",
      "loss: 0.767809  [ 6400/60000]\n",
      "loss: 0.536925  [12800/60000]\n",
      "loss: 0.769741  [19200/60000]\n",
      "loss: 0.683381  [25600/60000]\n",
      "loss: 0.660296  [32000/60000]\n",
      "loss: 0.728193  [38400/60000]\n",
      "loss: 0.729856  [44800/60000]\n",
      "loss: 0.732077  [51200/60000]\n",
      "loss: 0.700253  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.690507 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.641493  [    0/60000]\n",
      "loss: 0.746788  [ 6400/60000]\n",
      "loss: 0.518368  [12800/60000]\n",
      "loss: 0.754929  [19200/60000]\n",
      "loss: 0.671325  [25600/60000]\n",
      "loss: 0.647056  [32000/60000]\n",
      "loss: 0.709791  [38400/60000]\n",
      "loss: 0.718910  [44800/60000]\n",
      "loss: 0.718531  [51200/60000]\n",
      "loss: 0.685840  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.675513 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.620115  [    0/60000]\n",
      "loss: 0.727378  [ 6400/60000]\n",
      "loss: 0.501708  [12800/60000]\n",
      "loss: 0.741211  [19200/60000]\n",
      "loss: 0.660539  [25600/60000]\n",
      "loss: 0.635436  [32000/60000]\n",
      "loss: 0.692472  [38400/60000]\n",
      "loss: 0.708854  [44800/60000]\n",
      "loss: 0.706447  [51200/60000]\n",
      "loss: 0.672377  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.661608 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.600820  [    0/60000]\n",
      "loss: 0.709357  [ 6400/60000]\n",
      "loss: 0.486618  [12800/60000]\n",
      "loss: 0.728520  [19200/60000]\n",
      "loss: 0.651068  [25600/60000]\n",
      "loss: 0.625168  [32000/60000]\n",
      "loss: 0.676307  [38400/60000]\n",
      "loss: 0.699871  [44800/60000]\n",
      "loss: 0.695839  [51200/60000]\n",
      "loss: 0.659772  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.648757 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.583300  [    0/60000]\n",
      "loss: 0.692592  [ 6400/60000]\n",
      "loss: 0.473193  [12800/60000]\n",
      "loss: 0.716586  [19200/60000]\n",
      "loss: 0.642581  [25600/60000]\n",
      "loss: 0.616156  [32000/60000]\n",
      "loss: 0.661026  [38400/60000]\n",
      "loss: 0.692018  [44800/60000]\n",
      "loss: 0.686619  [51200/60000]\n",
      "loss: 0.647939  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.636871 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.567268  [    0/60000]\n",
      "loss: 0.676970  [ 6400/60000]\n",
      "loss: 0.461071  [12800/60000]\n",
      "loss: 0.705407  [19200/60000]\n",
      "loss: 0.634795  [25600/60000]\n",
      "loss: 0.608201  [32000/60000]\n",
      "loss: 0.646695  [38400/60000]\n",
      "loss: 0.685129  [44800/60000]\n",
      "loss: 0.678520  [51200/60000]\n",
      "loss: 0.636807  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.625868 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.552641  [    0/60000]\n",
      "loss: 0.662432  [ 6400/60000]\n",
      "loss: 0.450012  [12800/60000]\n",
      "loss: 0.694912  [19200/60000]\n",
      "loss: 0.627674  [25600/60000]\n",
      "loss: 0.601106  [32000/60000]\n",
      "loss: 0.633272  [38400/60000]\n",
      "loss: 0.679233  [44800/60000]\n",
      "loss: 0.671474  [51200/60000]\n",
      "loss: 0.626260  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.615680 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.539217  [    0/60000]\n",
      "loss: 0.648921  [ 6400/60000]\n",
      "loss: 0.439905  [12800/60000]\n",
      "loss: 0.685047  [19200/60000]\n",
      "loss: 0.621091  [25600/60000]\n",
      "loss: 0.594708  [32000/60000]\n",
      "loss: 0.620694  [38400/60000]\n",
      "loss: 0.674312  [44800/60000]\n",
      "loss: 0.665416  [51200/60000]\n",
      "loss: 0.616271  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.606245 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.526887  [    0/60000]\n",
      "loss: 0.636357  [ 6400/60000]\n",
      "loss: 0.430607  [12800/60000]\n",
      "loss: 0.675740  [19200/60000]\n",
      "loss: 0.614870  [25600/60000]\n",
      "loss: 0.588873  [32000/60000]\n",
      "loss: 0.608914  [38400/60000]\n",
      "loss: 0.670292  [44800/60000]\n",
      "loss: 0.660315  [51200/60000]\n",
      "loss: 0.606762  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.597502 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.515456  [    0/60000]\n",
      "loss: 0.624653  [ 6400/60000]\n",
      "loss: 0.421993  [12800/60000]\n",
      "loss: 0.666927  [19200/60000]\n",
      "loss: 0.608905  [25600/60000]\n",
      "loss: 0.583473  [32000/60000]\n",
      "loss: 0.597838  [38400/60000]\n",
      "loss: 0.667084  [44800/60000]\n",
      "loss: 0.655964  [51200/60000]\n",
      "loss: 0.597616  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.589390 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.504778  [    0/60000]\n",
      "loss: 0.613723  [ 6400/60000]\n",
      "loss: 0.414036  [12800/60000]\n",
      "loss: 0.658586  [19200/60000]\n",
      "loss: 0.603179  [25600/60000]\n",
      "loss: 0.578474  [32000/60000]\n",
      "loss: 0.587447  [38400/60000]\n",
      "loss: 0.664580  [44800/60000]\n",
      "loss: 0.652270  [51200/60000]\n",
      "loss: 0.588720  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.581874 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.494791  [    0/60000]\n",
      "loss: 0.603580  [ 6400/60000]\n",
      "loss: 0.406709  [12800/60000]\n",
      "loss: 0.650711  [19200/60000]\n",
      "loss: 0.597473  [25600/60000]\n",
      "loss: 0.573727  [32000/60000]\n",
      "loss: 0.577761  [38400/60000]\n",
      "loss: 0.662651  [44800/60000]\n",
      "loss: 0.649086  [51200/60000]\n",
      "loss: 0.580152  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.574895 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.485409  [    0/60000]\n",
      "loss: 0.594143  [ 6400/60000]\n",
      "loss: 0.399871  [12800/60000]\n",
      "loss: 0.643296  [19200/60000]\n",
      "loss: 0.591794  [25600/60000]\n",
      "loss: 0.569185  [32000/60000]\n",
      "loss: 0.568727  [38400/60000]\n",
      "loss: 0.661277  [44800/60000]\n",
      "loss: 0.646295  [51200/60000]\n",
      "loss: 0.571844  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.568407 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.476579  [    0/60000]\n",
      "loss: 0.585359  [ 6400/60000]\n",
      "loss: 0.393469  [12800/60000]\n",
      "loss: 0.636270  [19200/60000]\n",
      "loss: 0.586169  [25600/60000]\n",
      "loss: 0.564755  [32000/60000]\n",
      "loss: 0.560263  [38400/60000]\n",
      "loss: 0.660401  [44800/60000]\n",
      "loss: 0.643856  [51200/60000]\n",
      "loss: 0.563787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.562365 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.468234  [    0/60000]\n",
      "loss: 0.577157  [ 6400/60000]\n",
      "loss: 0.387516  [12800/60000]\n",
      "loss: 0.629587  [19200/60000]\n",
      "loss: 0.580471  [25600/60000]\n",
      "loss: 0.560419  [32000/60000]\n",
      "loss: 0.552339  [38400/60000]\n",
      "loss: 0.659939  [44800/60000]\n",
      "loss: 0.641649  [51200/60000]\n",
      "loss: 0.555950  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.556733 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.460333  [    0/60000]\n",
      "loss: 0.569502  [ 6400/60000]\n",
      "loss: 0.381946  [12800/60000]\n",
      "loss: 0.623206  [19200/60000]\n",
      "loss: 0.574762  [25600/60000]\n",
      "loss: 0.556196  [32000/60000]\n",
      "loss: 0.544928  [38400/60000]\n",
      "loss: 0.659848  [44800/60000]\n",
      "loss: 0.639661  [51200/60000]\n",
      "loss: 0.548320  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551479 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.452857  [    0/60000]\n",
      "loss: 0.562326  [ 6400/60000]\n",
      "loss: 0.376732  [12800/60000]\n",
      "loss: 0.617090  [19200/60000]\n",
      "loss: 0.569038  [25600/60000]\n",
      "loss: 0.552000  [32000/60000]\n",
      "loss: 0.538004  [38400/60000]\n",
      "loss: 0.660019  [44800/60000]\n",
      "loss: 0.637830  [51200/60000]\n",
      "loss: 0.540896  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.546570 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.445751  [    0/60000]\n",
      "loss: 0.555575  [ 6400/60000]\n",
      "loss: 0.371856  [12800/60000]\n",
      "loss: 0.611211  [19200/60000]\n",
      "loss: 0.563354  [25600/60000]\n",
      "loss: 0.547809  [32000/60000]\n",
      "loss: 0.531546  [38400/60000]\n",
      "loss: 0.660423  [44800/60000]\n",
      "loss: 0.636159  [51200/60000]\n",
      "loss: 0.533783  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.541981 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.438961  [    0/60000]\n",
      "loss: 0.549280  [ 6400/60000]\n",
      "loss: 0.367237  [12800/60000]\n",
      "loss: 0.605511  [19200/60000]\n",
      "loss: 0.557766  [25600/60000]\n",
      "loss: 0.543668  [32000/60000]\n",
      "loss: 0.525498  [38400/60000]\n",
      "loss: 0.660894  [44800/60000]\n",
      "loss: 0.634580  [51200/60000]\n",
      "loss: 0.526880  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.537679 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.432551  [    0/60000]\n",
      "loss: 0.543428  [ 6400/60000]\n",
      "loss: 0.362929  [12800/60000]\n",
      "loss: 0.600024  [19200/60000]\n",
      "loss: 0.552184  [25600/60000]\n",
      "loss: 0.539553  [32000/60000]\n",
      "loss: 0.519858  [38400/60000]\n",
      "loss: 0.661497  [44800/60000]\n",
      "loss: 0.633037  [51200/60000]\n",
      "loss: 0.520248  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.533640 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.426405  [    0/60000]\n",
      "loss: 0.537963  [ 6400/60000]\n",
      "loss: 0.358806  [12800/60000]\n",
      "loss: 0.594724  [19200/60000]\n",
      "loss: 0.546698  [25600/60000]\n",
      "loss: 0.535419  [32000/60000]\n",
      "loss: 0.514547  [38400/60000]\n",
      "loss: 0.662094  [44800/60000]\n",
      "loss: 0.631539  [51200/60000]\n",
      "loss: 0.513890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.529841 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.420510  [    0/60000]\n",
      "loss: 0.532888  [ 6400/60000]\n",
      "loss: 0.354913  [12800/60000]\n",
      "loss: 0.589634  [19200/60000]\n",
      "loss: 0.541306  [25600/60000]\n",
      "loss: 0.531276  [32000/60000]\n",
      "loss: 0.509594  [38400/60000]\n",
      "loss: 0.662694  [44800/60000]\n",
      "loss: 0.629987  [51200/60000]\n",
      "loss: 0.507787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.526265 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.414855  [    0/60000]\n",
      "loss: 0.528116  [ 6400/60000]\n",
      "loss: 0.351234  [12800/60000]\n",
      "loss: 0.584728  [19200/60000]\n",
      "loss: 0.536037  [25600/60000]\n",
      "loss: 0.527189  [32000/60000]\n",
      "loss: 0.504884  [38400/60000]\n",
      "loss: 0.663215  [44800/60000]\n",
      "loss: 0.628457  [51200/60000]\n",
      "loss: 0.501978  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.522891 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.409411  [    0/60000]\n",
      "loss: 0.523638  [ 6400/60000]\n",
      "loss: 0.347758  [12800/60000]\n",
      "loss: 0.580015  [19200/60000]\n",
      "loss: 0.530849  [25600/60000]\n",
      "loss: 0.522951  [32000/60000]\n",
      "loss: 0.500323  [38400/60000]\n",
      "loss: 0.663703  [44800/60000]\n",
      "loss: 0.626869  [51200/60000]\n",
      "loss: 0.496375  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.519701 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.404207  [    0/60000]\n",
      "loss: 0.519450  [ 6400/60000]\n",
      "loss: 0.344478  [12800/60000]\n",
      "loss: 0.575430  [19200/60000]\n",
      "loss: 0.525850  [25600/60000]\n",
      "loss: 0.518735  [32000/60000]\n",
      "loss: 0.496165  [38400/60000]\n",
      "loss: 0.664070  [44800/60000]\n",
      "loss: 0.625294  [51200/60000]\n",
      "loss: 0.491005  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.516684 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.399179  [    0/60000]\n",
      "loss: 0.515452  [ 6400/60000]\n",
      "loss: 0.341390  [12800/60000]\n",
      "loss: 0.571012  [19200/60000]\n",
      "loss: 0.521026  [25600/60000]\n",
      "loss: 0.514718  [32000/60000]\n",
      "loss: 0.492214  [38400/60000]\n",
      "loss: 0.664318  [44800/60000]\n",
      "loss: 0.623669  [51200/60000]\n",
      "loss: 0.485869  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.513825 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.394317  [    0/60000]\n",
      "loss: 0.511647  [ 6400/60000]\n",
      "loss: 0.338428  [12800/60000]\n",
      "loss: 0.566729  [19200/60000]\n",
      "loss: 0.516265  [25600/60000]\n",
      "loss: 0.510826  [32000/60000]\n",
      "loss: 0.488502  [38400/60000]\n",
      "loss: 0.664473  [44800/60000]\n",
      "loss: 0.621995  [51200/60000]\n",
      "loss: 0.481005  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.511112 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.389657  [    0/60000]\n",
      "loss: 0.508030  [ 6400/60000]\n",
      "loss: 0.335637  [12800/60000]\n",
      "loss: 0.562590  [19200/60000]\n",
      "loss: 0.511686  [25600/60000]\n",
      "loss: 0.507019  [32000/60000]\n",
      "loss: 0.484953  [38400/60000]\n",
      "loss: 0.664490  [44800/60000]\n",
      "loss: 0.620333  [51200/60000]\n",
      "loss: 0.476381  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.508529 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.385156  [    0/60000]\n",
      "loss: 0.504587  [ 6400/60000]\n",
      "loss: 0.332947  [12800/60000]\n",
      "loss: 0.558561  [19200/60000]\n",
      "loss: 0.507186  [25600/60000]\n",
      "loss: 0.503255  [32000/60000]\n",
      "loss: 0.481556  [38400/60000]\n",
      "loss: 0.664324  [44800/60000]\n",
      "loss: 0.618616  [51200/60000]\n",
      "loss: 0.472032  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.506066 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.380821  [    0/60000]\n",
      "loss: 0.501293  [ 6400/60000]\n",
      "loss: 0.330364  [12800/60000]\n",
      "loss: 0.554666  [19200/60000]\n",
      "loss: 0.502808  [25600/60000]\n",
      "loss: 0.499537  [32000/60000]\n",
      "loss: 0.478319  [38400/60000]\n",
      "loss: 0.663962  [44800/60000]\n",
      "loss: 0.616856  [51200/60000]\n",
      "loss: 0.467844  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.503711 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.376610  [    0/60000]\n",
      "loss: 0.498156  [ 6400/60000]\n",
      "loss: 0.327850  [12800/60000]\n",
      "loss: 0.550909  [19200/60000]\n",
      "loss: 0.498554  [25600/60000]\n",
      "loss: 0.495922  [32000/60000]\n",
      "loss: 0.475288  [38400/60000]\n",
      "loss: 0.663454  [44800/60000]\n",
      "loss: 0.615140  [51200/60000]\n",
      "loss: 0.463961  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.501462 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.372533  [    0/60000]\n",
      "loss: 0.495138  [ 6400/60000]\n",
      "loss: 0.325436  [12800/60000]\n",
      "loss: 0.547294  [19200/60000]\n",
      "loss: 0.494450  [25600/60000]\n",
      "loss: 0.492450  [32000/60000]\n",
      "loss: 0.472407  [38400/60000]\n",
      "loss: 0.662868  [44800/60000]\n",
      "loss: 0.613445  [51200/60000]\n",
      "loss: 0.460265  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499306 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.368569  [    0/60000]\n",
      "loss: 0.492279  [ 6400/60000]\n",
      "loss: 0.323106  [12800/60000]\n",
      "loss: 0.543839  [19200/60000]\n",
      "loss: 0.490458  [25600/60000]\n",
      "loss: 0.489066  [32000/60000]\n",
      "loss: 0.469641  [38400/60000]\n",
      "loss: 0.662155  [44800/60000]\n",
      "loss: 0.611684  [51200/60000]\n",
      "loss: 0.456786  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497241 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.364732  [    0/60000]\n",
      "loss: 0.489545  [ 6400/60000]\n",
      "loss: 0.320862  [12800/60000]\n",
      "loss: 0.540483  [19200/60000]\n",
      "loss: 0.486581  [25600/60000]\n",
      "loss: 0.485809  [32000/60000]\n",
      "loss: 0.466975  [38400/60000]\n",
      "loss: 0.661322  [44800/60000]\n",
      "loss: 0.609918  [51200/60000]\n",
      "loss: 0.453501  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.495255 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.361013  [    0/60000]\n",
      "loss: 0.486934  [ 6400/60000]\n",
      "loss: 0.318708  [12800/60000]\n",
      "loss: 0.537263  [19200/60000]\n",
      "loss: 0.482790  [25600/60000]\n",
      "loss: 0.482711  [32000/60000]\n",
      "loss: 0.464435  [38400/60000]\n",
      "loss: 0.660392  [44800/60000]\n",
      "loss: 0.608142  [51200/60000]\n",
      "loss: 0.450405  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.493343 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.357436  [    0/60000]\n",
      "loss: 0.484428  [ 6400/60000]\n",
      "loss: 0.316637  [12800/60000]\n",
      "loss: 0.534156  [19200/60000]\n",
      "loss: 0.479136  [25600/60000]\n",
      "loss: 0.479735  [32000/60000]\n",
      "loss: 0.461986  [38400/60000]\n",
      "loss: 0.659319  [44800/60000]\n",
      "loss: 0.606350  [51200/60000]\n",
      "loss: 0.447499  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.491499 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7387c147-38b1-40af-8721-d95bec952e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_1010.pth\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "torch.save(model.state_dict(), \"model_1010.pth\")\n",
    "print(\"Saved PyTorch Model State to model_1010.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e41f6e0-e509-4ddc-a300-57ea878b140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model_1010.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5c99cf-7001-460a-8728-50c5ae01c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29825b5b-9273-42b9-9a5d-67a3e3ba3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2936213d-7d4f-4662-afe8-81266fba1345",
   "metadata": {},
   "source": [
    "# Saving and Loading Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ca5ffa-ca19-4926-ab72-78c5110de58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/hangwu/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'vgg_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfeb14fb-c99a-4ce2-aeb6-b94def290729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('vgg_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eac725-1300-4e65-b931-f535005168fe",
   "metadata": {},
   "source": [
    "# Saving and Loading Models with Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f00f58-ddde-495e-abf3-13af1723e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'vgg_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "327648c2-8e22-4a39-9faf-b35f477cd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('vgg_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250606b5-fb2c-4daf-b121-f88984c981e7",
   "metadata": {},
   "source": [
    "# Exporting Model to ONNX\n",
    "PyTorch also has native ONNX export support. Given the dynamic nature of the PyTorch execution graph, however, the export process must traverse the execution graph to produce a persisted ONNX model. For this reason, a test variable of the appropriate size should be passed in to the export routine (in our case, we will create a dummy zero tensor of the correct size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "510f8907-0f36-41c8-876a-f265ff97628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,3,224,224))\n",
    "onnx.export(model, input_image, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89336f1-f4aa-4357-9fde-9ced1601e0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

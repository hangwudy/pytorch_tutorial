{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8099d269-8ce7-46bc-9745-219452721c3a",
   "metadata": {},
   "source": [
    "# TRANSFORMS\n",
    "\n",
    "The FashionMNIST features are in PIL Image format, and the labels are integers.\n",
    "For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
    "To make these transformations, we use ``ToTensor`` and ``Lambda``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfae218-8a55-4311-a2ac-df10f4f89b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a087f5-dc35-4b3c-bb69-1d09225335dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67028b65-246d-4dcd-be7e-a476fe2c5551",
   "metadata": {},
   "source": [
    "# ToTensor\n",
    "ToTensor converts a PIL image or NumPy ndarray into a FloatTensor. and scales the imageâ€™s pixel intensity values in the range [0., 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d3d3c-8953-49c6-8ea9-1c1a21190d97",
   "metadata": {},
   "source": [
    "# Lambda Transforms\n",
    "\n",
    "Lambda transforms apply any user-defined lambda function. \n",
    "\n",
    "Here, we define a function to turn the integer into a one-hot encoded tensor. \n",
    "\n",
    "It first creates a zero tensor of size 10 (the number of labels in our dataset) and calls scatter_ which assigns a value=1 on the index as given by the label y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1b1229-89e6-4d99-98a7-279cee7e3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42f30c-e233-4f7d-b836-c4c7c700abd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
